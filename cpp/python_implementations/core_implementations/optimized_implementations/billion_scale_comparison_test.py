#!/usr/bin/env python3
"""
Billion-Scale Comparison Test
============================

This script compares the performance of:
1. Original universal_brain_simulator.py (O(N¬≤) algorithms)
2. Optimized optimized_brain_simulator.py (O(N log K) algorithms)

At different scales to demonstrate the critical algorithmic improvements
for billion-scale neural simulation.
"""

import time
import sys
import os
import json
from typing import Dict, List, Any

# Add the current directory to Python path
sys.path.append(os.path.dirname(__file__))

# Import both implementations
try:
    from universal_brain_simulator import UniversalBrainSimulator, SimulationConfig as OriginalConfig
    from optimized_brain_simulator import OptimizedBrainSimulator, OptimizedSimulationConfig as OptimizedConfig
    print("‚úÖ Both implementations imported successfully!")
except ImportError as e:
    print(f"‚ùå Import failed: {e}")
    sys.exit(1)

class BillionScaleComparisonTest:
    """Compare O(N¬≤) vs O(N log K) performance at different scales"""
    
    def __init__(self):
        self.results = []
        self.max_test_time = 120  # 2 minutes max per test
    
    def test_scale(self, n_neurons: int, active_percentage: float, n_areas: int = 5, n_steps: int = 3):
        """Test both implementations at a specific scale"""
        k_active = int(n_neurons * active_percentage)
        
        print(f"\nüß™ Testing Scale: {n_neurons:,} neurons")
        print(f"   Active per area: {k_active:,}")
        print(f"   Total active: {k_active * n_areas:,}")
        print(f"   Steps: {n_steps}")
        
        # Calculate theoretical complexity
        n = n_neurons
        k = k_active
        
        # Original O(N¬≤) complexity
        o_n2_ops = n_areas * k * n * n
        
        # Optimized O(N log K) complexity
        o_n_log_k_ops = n_areas * n * (k.bit_length() - 1) if k > 0 else n_areas * n
        
        theoretical_speedup = o_n2_ops / o_n_log_k_ops if o_n_log_k_ops > 0 else float('inf')
        
        print(f"   Theoretical O(N¬≤) operations: {o_n2_ops:,.0e}")
        print(f"   Theoretical O(N log K) operations: {o_n_log_k_ops:,.0e}")
        print(f"   Theoretical speedup: {theoretical_speedup:,.0e}x")
        
        scale_results = {
            'n_neurons': n_neurons,
            'k_active': k_active,
            'n_areas': n_areas,
            'n_steps': n_steps,
            'theoretical_o_n2_ops': o_n2_ops,
            'theoretical_o_n_log_k_ops': o_n_log_k_ops,
            'theoretical_speedup': theoretical_speedup,
            'implementations': []
        }
        
        # Test Original Implementation (O(N¬≤))
        print(f"\nüî¨ Testing Original (O(N¬≤)) Implementation:")
        print("-" * 50)
        
        try:
            config = OriginalConfig(
                n_neurons=n_neurons,
                active_percentage=active_percentage,
                n_areas=n_areas,
                use_gpu=True,
                use_cuda_kernels=True,
                memory_efficient=True,
                sparse_mode=True
            )
            
            start_time = time.time()
            simulator = UniversalBrainSimulator(config)
            init_time = time.time() - start_time
            
            print(f"   Initialization: {init_time:.2f}s")
            
            sim_start = time.time()
            total_time = simulator.simulate(n_steps=n_steps, verbose=False)
            sim_time = time.time() - sim_start
            
            stats = simulator.get_performance_stats()
            
            print(f"   ‚úÖ Simulation completed: {sim_time:.2f}s")
            print(f"   Steps/sec: {stats['steps_per_second']:.1f}")
            print(f"   Neurons/sec: {stats['neurons_per_second']:,.0f}")
            print(f"   Memory: {stats['memory_usage_gb']:.2f}GB")
            
            result = {
                'name': 'Original (O(N¬≤))',
                'success': True,
                'init_time': init_time,
                'sim_time': sim_time,
                'total_time': init_time + sim_time,
                'steps_per_second': stats['steps_per_second'],
                'neurons_per_second': stats['neurons_per_second'],
                'memory_usage_gb': stats['memory_usage_gb'],
                'timeout': False
            }
            
        except Exception as e:
            print(f"   ‚ùå Failed: {e}")
            result = {
                'name': 'Original (O(N¬≤))',
                'success': False,
                'error': str(e),
                'timeout': False
            }
        
        scale_results['implementations'].append(result)
        
        # Test Optimized Implementation (O(N log K))
        print(f"\nüî¨ Testing Optimized (O(N log K)) Implementation:")
        print("-" * 50)
        
        try:
            config = OptimizedConfig(
                n_neurons=n_neurons,
                active_percentage=active_percentage,
                n_areas=n_areas,
                use_gpu=True,
                use_optimized_kernels=True,
                memory_efficient=True,
                sparse_mode=True
            )
            
            start_time = time.time()
            simulator = OptimizedBrainSimulator(config)
            init_time = time.time() - start_time
            
            print(f"   Initialization: {init_time:.2f}s")
            
            sim_start = time.time()
            total_time = simulator.simulate(n_steps=n_steps, verbose=False)
            sim_time = time.time() - sim_start
            
            stats = simulator.get_performance_stats()
            
            print(f"   ‚úÖ Simulation completed: {sim_time:.2f}s")
            print(f"   Steps/sec: {stats['steps_per_second']:.1f}")
            print(f"   Neurons/sec: {stats['neurons_per_second']:,.0f}")
            print(f"   Memory: {stats['memory_usage_gb']:.2f}GB")
            print(f"   Optimized kernels: {'‚úÖ' if stats['optimized_kernels_used'] else '‚ùå'}")
            
            result = {
                'name': 'Optimized (O(N log K))',
                'success': True,
                'init_time': init_time,
                'sim_time': sim_time,
                'total_time': init_time + sim_time,
                'steps_per_second': stats['steps_per_second'],
                'neurons_per_second': stats['neurons_per_second'],
                'memory_usage_gb': stats['memory_usage_gb'],
                'optimized_kernels_used': stats['optimized_kernels_used'],
                'timeout': False
            }
            
        except Exception as e:
            print(f"   ‚ùå Failed: {e}")
            result = {
                'name': 'Optimized (O(N log K))',
                'success': False,
                'error': str(e),
                'timeout': False
            }
        
        scale_results['implementations'].append(result)
        
        # Calculate actual speedup
        if len(scale_results['implementations']) == 2:
            orig = scale_results['implementations'][0]
            opt = scale_results['implementations'][1]
            
            if orig['success'] and opt['success']:
                actual_speedup = orig['sim_time'] / opt['sim_time'] if opt['sim_time'] > 0 else float('inf')
                print(f"\nüöÄ ACTUAL SPEEDUP: {actual_speedup:.2f}x")
                print(f"   Original: {orig['sim_time']:.2f}s")
                print(f"   Optimized: {opt['sim_time']:.2f}s")
                print(f"   Theoretical: {theoretical_speedup:,.0e}x")
                print(f"   Efficiency: {(actual_speedup / theoretical_speedup * 100):.1f}% of theoretical")
                
                scale_results['actual_speedup'] = actual_speedup
                scale_results['efficiency'] = actual_speedup / theoretical_speedup * 100 if theoretical_speedup > 0 else 0
            elif not orig['success'] and opt['success']:
                print(f"\nüöÄ BREAKTHROUGH: Original failed, Optimized succeeded!")
                print(f"   This demonstrates the critical importance of O(N log K) optimization")
                scale_results['breakthrough'] = True
            else:
                print(f"\n‚ùå Both implementations failed at this scale")
                scale_results['both_failed'] = True
        
        self.results.append(scale_results)
        return scale_results
    
    def run_billion_scale_tests(self):
        """Run comprehensive billion-scale comparison tests"""
        print("üöÄ BILLION-SCALE COMPARISON TEST")
        print("=" * 70)
        print("Comparing O(N¬≤) vs O(N log K) algorithms at increasing scales")
        print("Expected: O(N¬≤) should fail at large scales, O(N log K) should succeed")
        
        # Test scales (exponentially increasing)
        test_scales = [
            # Small scale (both should work)
            {"n_neurons": 100_000, "active_percentage": 0.01, "n_steps": 5},
            
            # Medium scale (both should work, speedup visible)
            {"n_neurons": 1_000_000, "active_percentage": 0.01, "n_steps": 3},
            
            # Large scale (speedup should be dramatic)
            {"n_neurons": 10_000_000, "active_percentage": 0.001, "n_steps": 1},
            
            # Very large scale (original may fail)
            {"n_neurons": 100_000_000, "active_percentage": 0.0001, "n_steps": 1},
            
            # Billion scale (original should fail, optimized should work)
            {"n_neurons": 1_000_000_000, "active_percentage": 0.00001, "n_steps": 1},
        ]
        
        for scale in test_scales:
            try:
                self.test_scale(**scale)
            except KeyboardInterrupt:
                print(f"\n‚èπÔ∏è  Test interrupted by user")
                break
            except Exception as e:
                print(f"‚ùå Scale {scale['n_neurons']:,} failed: {e}")
                continue
        
        self.print_summary()
        self.save_results()
    
    def print_summary(self):
        """Print comprehensive summary"""
        print(f"\nüìä BILLION-SCALE COMPARISON SUMMARY")
        print("=" * 70)
        
        for result in self.results:
            print(f"\nScale: {result['n_neurons']:,} neurons")
            print(f"  Active per area: {result['k_active']:,}")
            print(f"  Theoretical speedup: {result['theoretical_speedup']:,.0e}x")
            
            if 'actual_speedup' in result:
                print(f"  üöÄ Actual speedup: {result['actual_speedup']:.2f}x")
                print(f"  üìà Efficiency: {result['efficiency']:.1f}% of theoretical")
            elif 'breakthrough' in result:
                print(f"  üéØ BREAKTHROUGH: Original failed, Optimized succeeded!")
            elif 'both_failed' in result:
                print(f"  ‚ùå Both implementations failed")
            
            for impl in result['implementations']:
                if impl['success']:
                    print(f"    {impl['name']}: {impl['sim_time']:.2f}s, {impl['neurons_per_second']:,.0f} neurons/sec")
                else:
                    print(f"    {impl['name']}: ‚ùå {impl['error']}")
        
        # Calculate performance trends
        print(f"\nüìà PERFORMANCE TRENDS")
        print("-" * 40)
        
        successful_results = [r for r in self.results if 'actual_speedup' in r]
        if len(successful_results) >= 2:
            print("Speedup increases with scale:")
            for i in range(1, len(successful_results)):
                prev = successful_results[i-1]
                curr = successful_results[i]
                
                scale_ratio = curr['n_neurons'] / prev['n_neurons']
                speedup_ratio = curr['actual_speedup'] / prev['actual_speedup']
                
                print(f"  {prev['n_neurons']:,} ‚Üí {curr['n_neurons']:,} neurons:")
                print(f"    Scale increase: {scale_ratio:.1f}x")
                print(f"    Speedup increase: {speedup_ratio:.1f}x")
        
        print(f"\nüéØ KEY INSIGHTS:")
        print(f"  - O(N¬≤) algorithms become impractical at large scales")
        print(f"  - O(N log K) algorithms can handle billion-scale efficiently")
        print(f"  - Speedup increases dramatically with scale")
        print(f"  - This demonstrates why algorithmic optimization is critical!")
    
    def save_results(self):
        """Save results to JSON file"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"billion_scale_comparison_{timestamp}.json"
        
        with open(filename, 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print(f"\nüíæ Results saved to: {filename}")

def main():
    """Run the billion-scale comparison test"""
    print("üß† Billion-Scale Comparison Test")
    print("=" * 60)
    print("This test compares O(N¬≤) vs O(N log K) algorithms:")
    print("  - Small scales: Both work, modest speedup")
    print("  - Medium scales: Speedup becomes significant")
    print("  - Large scales: O(N¬≤) becomes impractical")
    print("  - Billion scale: Only O(N log K) can handle it")
    print("  - This demonstrates why algorithmic optimization is critical!")
    
    # Create test instance
    test = BillionScaleComparisonTest()
    
    # Run tests
    test.run_billion_scale_tests()
    
    print(f"\nüéØ CONCLUSION:")
    print(f"  - O(N¬≤) algorithms fail at large scales")
    print(f"  - O(N log K) algorithms enable billion-scale simulation")
    print(f"  - Speedup increases exponentially with scale")
    print(f"  - This is why we implemented the optimized algorithms!")

if __name__ == "__main__":
    main()

